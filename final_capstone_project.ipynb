{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import glob\n",
    "import time\n",
    "from textdistance import levenshtein\n",
    "\n",
    "# import os\n",
    "# import boto3\n",
    "# import statistics\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# init_notebook_mode(connected=False)\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import umap\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.cluster import DBSCAN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=8461193216, available=3370409984, percent=60.2, used=5090783232, free=3370409984)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in commentors\n",
    "commentors = pd.read_csv('data/cleaned/comments.csv', usecols=['commentor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve commentors suspected to be the same individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165718"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique commentors\n",
    "commentors.commentor.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"All Eyez On Me\" in theaters NOW!!!',\n",
       "       '\"All Eyez On Me\" in theaters june 16 2017'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get an example of a potential single commentor under two different usernames\n",
    "commentors[commentors.commentor.str.contains(\"All Eyez On Me\")]['commentor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['*********************************************************************************** The Native Americans are not r*dsk*ns. They are human beings like you and me. FTTR! - Fail To The Racists!',\n",
       "       '*********************************************************************************** The Native Americans are not r*dsk*ns. They are human beings like you and me. FTTR! - Fail To The Racists! ***********************************************************',\n",
       "       'The Native Americans are not r*dsk*ns. They are human beings like you and me. FTTR! - Fail To The Racists!',\n",
       "       '*********************************************************************** The Native Americans are not r*dsk*ns. They are human beings like you and me. FTTR! - Fail To The Racists! ***********************************************************************',\n",
       "       'The Native Americans are not r*dsk*ns. They are human beings. FTTR! - Fail To The Racists!',\n",
       "       'The Native Americans are not r*dsk*ns! They are human beings! FTTR! - Fail To The Racistskins!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get another example\n",
    "commentors[commentors.commentor.str.contains(\"Native Americans\")]['commentor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('\"All Eyez On Me\" in theaters NOW!!!','\"All Eyez On Me\" in theaters june 16 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_commentors = pd.DataFrame(commentors.commentor.unique())\n",
    "unique_commentors.columns = ['commentor']\n",
    "unique_commentors = unique_commentors.sort_values(by=['commentor']).reset_index(drop=True)\n",
    "df = unique_commentors[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create df of unique commentor's usernames\n",
    "unique_commentors = pd.DataFrame(commentors.commentor.unique())\n",
    "unique_commentors.columns = ['commentor']\n",
    "unique_commentors = unique_commentors.sort_values(by=['commentor']).reset_index(drop=True)\n",
    "\n",
    "increment = 1000\n",
    "for i in range(0,round(unique_commentors.shape[0]), increment):\n",
    "    start_time = time.time()\n",
    "    print(i)\n",
    "    df = unique_commentors[i:i+increment]\n",
    "\n",
    "    # Compare usernames to find potential split entities\n",
    "    potential_matches = list()\n",
    "    for name in df.commentor:\n",
    "        if len(name) < 10:\n",
    "            continue\n",
    "        for other_name in df.commentor:\n",
    "            if name != other_name and len(other_name) > 10:\n",
    "                score = fuzz.partial_ratio(name, other_name)\n",
    "                if score >= 83:\n",
    "                    potential_matches.append([name,other_name,score])\n",
    "\n",
    "    potential_matches_df = pd.DataFrame(potential_matches, columns=['username1','username2','score'])\n",
    "    potential_matches_df.to_csv(f'tmp_entity_resolution/{i}.csv', header=False, index=False)\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54628, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in resolved usernames\n",
    "resolved_usernames_files = glob.glob('tmp_entity_resolution/*.csv')\n",
    "data = list()\n",
    "\n",
    "for filename in resolved_usernames_files:\n",
    "    df = pd.read_csv(filename, names=['commentor1','commentor2','score'])\n",
    "    data.append(df)\n",
    "\n",
    "resolved_usernames = pd.concat(data, axis=0, ignore_index=True)\n",
    "resolved_usernames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate various ratios\n",
    "resolved_usernames['ratio'] = resolved_usernames.apply(lambda x: fuzz.ratio(x.commentor1, x.commentor2), axis=1)\n",
    "resolved_usernames['partial_token_set_ratio'] = resolved_usernames.apply(lambda x: fuzz.partial_token_set_ratio(x.commentor1, x.commentor2), axis=1)\n",
    "resolved_usernames['token_sort_ratio'] = resolved_usernames.apply(lambda x: fuzz.token_sort_ratio(x.commentor1, x.commentor2), axis=1)\n",
    "resolved_usernames['WRatio'] = resolved_usernames.apply(lambda x: fuzz.WRatio(x.commentor1, x.commentor2), axis=1)\n",
    "resolved_usernames['avg_score'] = resolved_usernames[['score', 'ratio','partial_token_set_ratio','token_sort_ratio']].mean(axis=1)\n",
    "high_confidence_matches = resolved_usernames[resolved_usernames.WRatio >= 88]\n",
    "high_confidence_matches.to_csv('tmp_resolved_entities/high_confidence_matches.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentor1</th>\n",
       "      <th>commentor2</th>\n",
       "      <th>score</th>\n",
       "      <th>ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>WRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53816</th>\n",
       "      <td>joetoronto</td>\n",
       "      <td>joetoronto and billswillnevermove in a nacho cheese match</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>65.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53817</th>\n",
       "      <td>joetoronto</td>\n",
       "      <td>joetoronto has 50 plus names on here</td>\n",
       "      <td>100</td>\n",
       "      <td>43</td>\n",
       "      <td>100</td>\n",
       "      <td>43</td>\n",
       "      <td>71.5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53818</th>\n",
       "      <td>joetoronto</td>\n",
       "      <td>joetoronto has 50 plus names on here including Lawrence</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>65.5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53819</th>\n",
       "      <td>joetoronto</td>\n",
       "      <td>joetoronto has 50 plus names on here including ee00ee</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>66.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53820</th>\n",
       "      <td>joetoronto</td>\n",
       "      <td>joetoronto has an unhealthy obsession with Mack and Trubisky</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>64.5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commentor1  \\\n",
       "53816  joetoronto   \n",
       "53817  joetoronto   \n",
       "53818  joetoronto   \n",
       "53819  joetoronto   \n",
       "53820  joetoronto   \n",
       "\n",
       "                                                         commentor2  score  \\\n",
       "53816     joetoronto and billswillnevermove in a nacho cheese match    100   \n",
       "53817                          joetoronto has 50 plus names on here    100   \n",
       "53818       joetoronto has 50 plus names on here including Lawrence    100   \n",
       "53819         joetoronto has 50 plus names on here including ee00ee    100   \n",
       "53820  joetoronto has an unhealthy obsession with Mack and Trubisky    100   \n",
       "\n",
       "       ratio  partial_token_set_ratio  token_sort_ratio  avg_score  WRatio  \n",
       "53816     30                      100                30       65.0      90  \n",
       "53817     43                      100                43       71.5      90  \n",
       "53818     31                      100                31       65.5      90  \n",
       "53819     32                      100                32       66.0      90  \n",
       "53820     29                      100                29       64.5      90  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a potential single commentor operating under different usernames \n",
    "high_confidence_matches[high_confidence_matches.commentor1 == 'joetoronto'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping between duplicate name and resolved name\n",
    "resolved_commentors = dict()\n",
    "for i in range(0, len(high_confidence_matches)):\n",
    "    commentor1 = high_confidence_matches['commentor1'].iloc[i]\n",
    "    commentor2 = high_confidence_matches['commentor2'].iloc[i]\n",
    "    if commentor2 not in resolved_commentors.keys():\n",
    "        if commentor1 not in resolved_commentors.keys():\n",
    "            resolved_commentors[commentor2] = commentor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping to original data\n",
    "commentors = pd.read_csv('data/cleaned/comments.csv')\n",
    "commentors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pft",
   "language": "python",
   "name": "pft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
