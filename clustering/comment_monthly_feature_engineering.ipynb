{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Splitting the comments into monthly datasets then engineering features for each commentor/month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cleaned comments and article data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5689832, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load cleaned comment data\n",
    "comments = pd.read_csv('../data/cleaned/comments.csv', header=0, parse_dates=['scrape_datetime','comment_datetime_clean'])\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202862, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load cleaned article data\n",
    "articles = pd.read_csv('../data/cleaned/articles.csv', header=0, parse_dates=['scrape_datetime','post_datetime'])\n",
    "articles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add article post datetime to comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_merge = comments.merge(articles[['article_url','post_datetime']], how='left', on='article_url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data by month and engineer features by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Period('2008', 'A-DEC'), Period('2020', 'A-DEC'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the periods that will make up the number of monthly datasets\n",
    "comments_merge['post_datetime_year'] = pd.to_datetime(comments_merge['post_datetime']).dt.to_period('Y')\n",
    "comments_merge.post_datetime_year.min(), comments_merge.post_datetime_year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \n",
      "\n",
      "2020\n",
      "2019\n",
      "2018\n",
      "2017\n",
      "2016\n",
      "2015\n",
      "2014\n",
      "2013\n",
      "2012\n",
      "2011\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# How many yearly datasets\n",
    "print(comments_merge.post_datetime_year.nunique(), '\\n')\n",
    "\n",
    "# Iterate through the months to create the datasets\n",
    "for year in comments_merge.post_datetime_year.unique():\n",
    "    \n",
    "    # To skip NaT values\n",
    "    if len(str(year)) != 4:\n",
    "        continue\n",
    "    \n",
    "    # Filter data\n",
    "    comments = comments_merge[comments_merge.post_datetime_year == year]\n",
    "    print(year)\n",
    "    \n",
    "    # Calculate the total number of comments by each commentor\n",
    "    commentor_features = pd.DataFrame(comments.groupby(['commentor']).size())\n",
    "    commentor_features['commentor'] = commentor_features.index\n",
    "    commentor_features.columns = ['total_number_of_comments','commentor']\n",
    "    commentor_features.to_csv(f'../data/cluster_features_monthly/01_total_number_of_comments_{year}.csv', header=True, index=True)\n",
    "\n",
    "    # Calculate the number of unique articles the commentor commented on\n",
    "    unique_articles = comments.groupby(['commentor','article_url']).size()\n",
    "    unique_articles_df = pd.DataFrame(unique_articles.groupby(['commentor']).size())\n",
    "    unique_articles_df.columns = ['number_of_articles_commented_on']\n",
    "    unique_articles_df.to_csv(f'../data/cluster_features_monthly/02_unique_articles_df_{year}.csv', header=True, index=True)\n",
    "    # unique_articles_df.head()\n",
    "    \n",
    "    # Calculate the number of unique articles the commentor commented on exactly once\n",
    "    unique_articles_single_comment = comments.groupby(['commentor','article_url']).size()\n",
    "    unique_articles_single_comment_df = pd.DataFrame(unique_articles_single_comment)\n",
    "    unique_articles_single_comment_df = unique_articles_single_comment_df[unique_articles_single_comment_df[0] == 1]\n",
    "    unique_articles_single_comment_df = pd.DataFrame(unique_articles_single_comment_df.groupby(['commentor']).size())\n",
    "    unique_articles_single_comment_df.columns = ['number_of_articles_w_exactly_one_comment']\n",
    "    unique_articles_single_comment_df.to_csv(f'../data/cluster_features_monthly/03_unique_articles_single_comment_df_{year}.csv', header=True, index=True)\n",
    "    # unique_articles_single_comment_df.head()\n",
    "    \n",
    "    # Calculate the number of unique articles the commentor commented on more than once\n",
    "    unique_articles_mulitple_comment = comments.groupby(['commentor','article_url']).size()\n",
    "    unique_articles_mulitple_comment_df = pd.DataFrame(unique_articles_mulitple_comment)\n",
    "    unique_articles_mulitple_comment_df = unique_articles_mulitple_comment_df[unique_articles_mulitple_comment_df[0] > 1]\n",
    "    unique_articles_mulitple_comment_df = pd.DataFrame(unique_articles_mulitple_comment_df.groupby(['commentor']).size())\n",
    "    unique_articles_mulitple_comment_df.columns = ['number_of_articles_w_more_than_one_comment']\n",
    "    unique_articles_mulitple_comment_df.to_csv(f'../data/cluster_features_monthly/04_unique_articles_mulitple_comment_df_{year}.csv', header=True, index=True)\n",
    "    # unique_articles_mulitple_comment_df.head()\n",
    "    \n",
    "    # Calculate how long (in days) a commentor has been active on pft\n",
    "    commentor_activity_duration = comments.groupby(['commentor']).agg({'comment_datetime_clean':['min','max']})\n",
    "    commentor_activity_duration.columns = commentor_activity_duration.columns.droplevel()\n",
    "    commentor_activity_duration['commentor_activity_duration_in_days'] = (commentor_activity_duration['max'] - commentor_activity_duration['min']).dt.days\n",
    "    commentor_activity_duration.to_csv(f'../data/cluster_features_monthly/05_commentor_activity_duration_{year}.csv', header=True, index=True)\n",
    "    # commentor_activity_duration.head()\n",
    "    \n",
    "    # Calcualte the length of the commentor's username\n",
    "    commentor_username_length = comments.groupby(['commentor']).size()\n",
    "    commentor_username_length = pd.DataFrame(commentor_username_length)\n",
    "    commentor_username_length['username'] = commentor_username_length.index\n",
    "    commentor_username_length['username_length'] = commentor_username_length['username'].str.len()\n",
    "    commentor_username_length.drop([0], axis=1, inplace=True)\n",
    "\n",
    "    # Calculate the number of letters, numbers, and spaces in the commentor's username\n",
    "    commentor_username_length['username_alpha_chars'] = commentor_username_length['username'].apply(lambda username: sum(x.isalpha() for x in username))\n",
    "    commentor_username_length['username_numeric_chars'] = commentor_username_length['username'].apply(lambda username: sum(x.isdigit() for x in username))\n",
    "    commentor_username_length['username_space_chars'] = commentor_username_length['username'].apply(lambda username: sum(x.isspace() for x in username))\n",
    "    commentor_username_length.to_csv(f'../data/cluster_features_monthly/06_commentor_username_length_{year}.csv', header=True, index=True)\n",
    "    # commentor_username_length.head()\n",
    "    \n",
    "    # Calculate the mean, median, min and max length of comments (characters)\n",
    "    comments['comment_body_length'] = comments['comment_body'].str.len()\n",
    "    commentor_comment_body_metrics = comments.groupby(['commentor']).agg({'comment_body_length':['mean','median','min','max','sum']})\n",
    "    commentor_comment_body_metrics.columns = commentor_comment_body_metrics.columns.droplevel()\n",
    "    commentor_comment_body_metrics.columns = ['comment_length_mean','comment_length_median','comment_length_min','comment_length_max','comment_length_total']\n",
    "    commentor_comment_body_metrics.to_csv(f'../data/cluster_features_monthly/07_commentor_comment_body_metrics_{year}.csv', header=True, index=True)\n",
    "    # commentor_comment_body_metrics.head()\n",
    "    \n",
    "    # Calculate the average, median, min, max hours between when article was published and comment was made\n",
    "    articles_w_dates = articles.drop_duplicates(subset=['article_url','post_datetime'])\n",
    "    comments_between = pd.merge(comments, articles_w_dates[['article_url','post_datetime']], how='left', on='article_url')\n",
    "    comments_between = comments_between[(comments_between.comment_datetime_clean >= comments_between.post_datetime_x)]\n",
    "    comments_between['hours_btween'] = (comments_between.comment_datetime_clean - comments_between.post_datetime_x) / pd.Timedelta(hours=1)\n",
    "\n",
    "    hours_between_metrics = comments_between.groupby(['commentor']).agg({'hours_btween':['mean','median','min','max']})\n",
    "    hours_between_metrics.columns = hours_between_metrics.columns.droplevel()\n",
    "    hours_between_metrics.columns = ['hours_between_mean','hours_between_median','hours_between_min','hours_between_max']\n",
    "    hours_between_metrics.to_csv(f'../data/cluster_features_monthly/08_hours_between_metrics_{year}.csv', header=True, index=True)\n",
    "    # hours_between_metrics.head()\n",
    "    \n",
    "    # Calculate which days of the week comments were made on\n",
    "    comments['comment_date_dow'] = comments['comment_datetime_clean'].dt.day_name()\n",
    "    comments_dow = pd.pivot_table(comments[['article_url','commentor','comment_date_dow']], index=['commentor'],\n",
    "                        columns=['comment_date_dow'], aggfunc='count', fill_value=0)\n",
    "    comments_dow.columns = comments_dow.columns.droplevel()\n",
    "    comments_dow.columns = ['comments_on_' + c for c in comments_dow.columns]\n",
    "    comments_dow.to_csv(f'../data/cluster_features_monthly/09_comments_dow_{year}.csv', header=True, index=True)\n",
    "    # comments_dow.head()\n",
    "    \n",
    "    # Calculate which hours of the day comments were made on\n",
    "    comments['comment_date_hour'] = comments['comment_datetime_clean'].dt.hour\n",
    "    comments_hour = pd.pivot_table(comments[['article_url','commentor','comment_date_hour']], index=['commentor'],\n",
    "                        columns=['comment_date_hour'], aggfunc='count', fill_value=0)\n",
    "    comments_hour.columns = comments_hour.columns.droplevel()\n",
    "    comments_hour.columns = ['comments_on_hour_' + str(c) for c in comments_hour.columns]\n",
    "    comments_hour.to_csv(f'../data/cluster_features_monthly/10_comments_hour_{year}.csv', header=True, index=True)\n",
    "    # comments_hour.head()\n",
    "    \n",
    "    # Count number of comment made \"in-season\" vs \"off-season\"\n",
    "    # In-season being between 9/1 and 2/1, inclusive\n",
    "    comments['comment_date_month'] = comments['comment_datetime_clean'].dt.month\n",
    "    comments['in_season_flag'] = np.where((comments['comment_date_month'] >= 9) | (comments['comment_date_month'] <= 2), 1, 0)\n",
    "    in_season_comments = comments.groupby(['commentor']).agg({'in_season_flag':['count','sum']})\n",
    "    in_season_comments.columns = in_season_comments.columns.droplevel()\n",
    "    in_season_comments.columns = ['total_comments','number_in_season_comments']\n",
    "    in_season_comments['number_out_season_comments'] = in_season_comments['total_comments'] - in_season_comments['number_in_season_comments']\n",
    "    in_season_comments.to_csv(f'../data/cluster_features_monthly/11_in_season_comments_{year}.csv', header=True, index=True)\n",
    "    # in_season_comments.head()\n",
    "    \n",
    "    # Calculate the most number of comments each commentor posted in a single day\n",
    "    commentor_max_comments = pd.DataFrame(comments.groupby(['commentor','comment_datetime_clean']).size()).reset_index()\n",
    "    commentor_max_comments_df = pd.DataFrame(commentor_max_comments.groupby(['commentor'])[0].max())\n",
    "    commentor_max_comments_df.columns = ['max_number_comments_in_single_day']\n",
    "    commentor_max_comments_df.to_csv(f'../data/cluster_features_monthly/12_commentor_max_comments_df_{year}.csv', header=True, index=True)\n",
    "    # commentor_max_comments_df.head()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pft",
   "language": "python",
   "name": "pft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
