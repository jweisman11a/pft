{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import boto3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The collection of the data was done separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3 bucket created for ML Guild project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload articles and comment files to S3\n",
    "articles = 'data/cleaned/articles.csv'\n",
    "comments = 'data/cleaned/comments.csv'\n",
    "files = [articles, comments]\n",
    "\n",
    "# Ensure credentials file is reachable in Windows OS\n",
    "# https://docs.aws.amazon.com/credref/latest/refdocs/file-location.html\n",
    "# %USERPROFILE%\\.aws\\credentials\n",
    "\n",
    "# Check if bucket exists\n",
    "s3 = boto3.client('s3', verify=False)\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# If bucket doesn't exist, create it\n",
    "bucket_name = 'ml-guild-project-pft-comments'\n",
    "if bucket_name not in response['Buckets']:\n",
    "    print('Creating bucket...')\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print('Bucket created')\n",
    "\n",
    "# Check if data is already uploaded to S3 bucket\n",
    "keys = []\n",
    "for key in s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "    keys.append(key['Key'])\n",
    "print(sorted(keys))\n",
    "    \n",
    "# Upload data to S3 bucket if keys not found\n",
    "if sorted(keys) != sorted(files):\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as data:\n",
    "            s3.upload_fileobj(data, 'ml-guild-project-pft-comments', file)\n",
    "            print(f'{file} has been uploaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cleaned data\n",
    "for key in keys:\n",
    "    s3.download_file(bucket_name, key, key)\n",
    "    print(f'{key} has been download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "comments_all = pd.read_csv('data/cleaned/comments.csv', parse_dates=['comment_datetime_clean'])\n",
    "articles = pd.read_csv('data/cleaned/articles.csv', header=0, parse_dates=['scrape_datetime','post_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comments_all.shape)\n",
    "print(articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers and single commenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Single commenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What % of commentors only engaged exactly once/year?\n",
    "comments_all['year'] = comments_all['comment_datetime_clean'].dt.year\n",
    "percent_single_commentors = list()\n",
    "for year in comments_all.year.unique():\n",
    "    one_year = comments_all[comments_all.year == year]\n",
    "    table = one_year.commentor.value_counts().reset_index()\n",
    "    num_unique_commentors = table.shape[0]\n",
    "    num_single_commentors = table[table.commentor == 1].shape[0]\n",
    "    print(f'{year}: {num_single_commentors / num_unique_commentors:,.2f}%, {num_single_commentors} / {num_unique_commentors}')\n",
    "    percent_single_commentors.append(num_single_commentors / num_unique_commentors)\n",
    "    \n",
    "f'mean: {np.mean(percent_single_commentors)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What % of commentors only engaged exactly once across the entire dataset?\n",
    "table = comments_all.commentor.value_counts().reset_index()\n",
    "num_unique_commentors = table.shape[0]\n",
    "num_single_commentors = table[table.commentor == 1].shape[0]\n",
    "print(f'all years: {num_single_commentors / num_unique_commentors:,.2f}%, {num_single_commentors} / {num_unique_commentors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Commenters above 5 stddev (\"super users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's determine a cut-off for \"outlier\"\n",
    "num_nonsingle_commentors = table[table.commentor != 1]['commentor'].values\n",
    "five_stdev_cutoff = statistics.stdev(num_nonsingle_commentors) * 5\n",
    "print(sum(num_nonsingle_commentors > five_stdev_cutoff))\n",
    "print(sum(num_nonsingle_commentors > five_stdev_cutoff) / len(num_nonsingle_commentors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove single commentors and those above cut-off\n",
    "table = comments_all.commentor.value_counts().reset_index()\n",
    "table_outliers_removed = table[(table.commentor != 1) & (table.commentor < five_stdev_cutoff)]\n",
    "table_outliers_removed.columns = ['commentor','num_comments']\n",
    "commentors = table_outliers_removed.commentor.values\n",
    "print(table_outliers_removed.commentor.nunique())\n",
    "\n",
    "# Filter comment df based on cut-offs\n",
    "comments = comments_all[comments_all.commentor.isin(commentors)]\n",
    "comments.to_csv('data/in_process/comments.csv', header=True, index=False)\n",
    "print(comments_all.shape)\n",
    "print(comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize remaining commentors distribution\n",
    "table = comments.commentor.value_counts().reset_index()\n",
    "fig = go.Figure(data=[go.Histogram(x=table.commentor.values, histfunc='sum', histnorm='probability', cumulative_enabled=False)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer features to use in clustering (all years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Calculate the total number of comments by each commenter\n",
    "num_comments = comments.commentor.value_counts()\n",
    "num_comments.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Calculate the total number of unique articles commented on by each commenter\n",
    "comments_by_articles = comments.groupby('commentor')['article_url'].nunique()\n",
    "comments_by_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Calculate the time of day commenters posted\n",
    "def times_of_date_by_hour(hour):\n",
    "    if hour >= 5 and hour < 12:\n",
    "        return 'morning'\n",
    "    if hour >= 12 and hour < 17:\n",
    "        return 'afternoon'\n",
    "    if hour >= 17 and hour < 21:\n",
    "        return 'evening'\n",
    "    if hour >= 21 or hour < 5:\n",
    "            return 'night'\n",
    "    \n",
    "comments['comment_time_of_day'] = comments.comment_datetime_clean.dt.hour.apply(times_of_date_by_hour)\n",
    "comments_by_time_of_day = pd.pivot_table(comments[['article_url','comment_time_of_day','commentor']],\n",
    "                                         index=['commentor'],\n",
    "                                         columns=['comment_time_of_day'],\n",
    "                                         aggfunc='count',\n",
    "                                         fill_value=0\n",
    "                                        )\n",
    "comments_by_time_of_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Calculate the number of unique articles the commentor commented on more than once\n",
    "unique_articles_mulitple_comment = comments.groupby(['commentor','article_url']).size()\n",
    "unique_articles_mulitple_comment_df = pd.DataFrame(unique_articles_mulitple_comment)\n",
    "unique_articles_mulitple_comment_df = unique_articles_mulitple_comment_df[unique_articles_mulitple_comment_df[0] > 1]\n",
    "unique_articles_mulitple_comment_df = pd.DataFrame(unique_articles_mulitple_comment_df.groupby(['commentor']).size())\n",
    "unique_articles_mulitple_comment_df.columns = ['number_of_articles_w_more_than_one_comment']\n",
    "unique_articles_mulitple_comment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Calculate how long (in days) a commentor has been active on pft\n",
    "commentor_activity_duration = comments.groupby(['commentor']).agg({'comment_datetime_clean':['min','max']})\n",
    "commentor_activity_duration.columns = commentor_activity_duration.columns.droplevel()\n",
    "commentor_activity_duration['commentor_activity_duration_in_days'] = (commentor_activity_duration['max'] - commentor_activity_duration['min']).dt.days\n",
    "commentor_activity_duration.drop(['min','max'], axis=1, inplace=True)\n",
    "commentor_activity_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Calculate the total number of characters, words, and sentences written by the commenter\n",
    "comments['comment_body_length'] = comments['comment_body'].str.replace('\\n','').str.len()\n",
    "# comments['comment_word_tokens'] = comments['comment_body'].apply(lambda x: len(word_tokenize(x))\n",
    "# comments['comment_sent_tokens'] = comments['comment_body'].apply(lambda x: len(sent_tokenize(x))\n",
    "\n",
    "comments.head()\n",
    "\n",
    "# sent_tokenize, word_tokenize\n",
    "\n",
    "# commentor_comment_body_metrics = comments.groupby(['commentor']).agg({'comment_body_length':['mean','median','min','max','sum']})\n",
    "# commentor_comment_body_metrics.columns = commentor_comment_body_metrics.columns.droplevel()\n",
    "# commentor_comment_body_metrics.columns = ['comment_length_mean','comment_length_median','comment_length_min','comment_length_max','comment_length_total']\n",
    "# commentor_comment_body_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore features before dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and reduce dimensionality using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster data using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine feature importance using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pft",
   "language": "python",
   "name": "pft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
